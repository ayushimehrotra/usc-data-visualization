# Video and Graph-Based Visualizations to Show Performance of Modeling Engagement

For more information, please go to https://viterbik12.usc.edu/wp-content/uploads/2022/08/S22-Mehrotra-A-Poster-Final.pdf

## Introduction

Socially Assistive Robots (SAR) are a subset of human-robot interactions (HRI) and are focused on aiding learning and developing social skills. The implementation of SARs with children on the autism spectrum has shown significant results and advances. One of these advancements is utilizing machine learning to alter the robot’s behaviors based on the child’s engagement with the activity. The inputted features into the machine learning model can be locations of facial features and facial action units. By integrating computer vision, the effectiveness of the activities to develop cognitive abilities in the child increased.  

On the other hand, data visualizations translate information into a visual medium: graphs, videos, pictures, or maps. This paper contributes two visualizations that are used to show the performance of the robot’s machine learning model to determine engagement based on a user-inputted set of features F. 

`Graph-Based-visualization.ipynb` is the graph-based visualization and `Video-based-Visualization.ipynb` is the video based visualization
